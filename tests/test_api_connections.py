#!/usr/bin/env python3
"""
API Connection Tests for MevzuatGPT
Tests OpenAI and Groq API connections
"""

import asyncio
import os
import sys
import time
from typing import Dict, Any

# Add project root to path
sys.path.append('/home/runner/workspace')

from services.groq_service import GroqService
from services.embedding_service import EmbeddingService
from core.config import Settings

class APIConnectionTester:
    """Test API connections for OpenAI and Groq"""
    
    def __init__(self):
        self.settings = Settings()
        self.results = {}
    
    async def test_openai_embedding(self) -> Dict[str, Any]:
        """Test OpenAI embedding API connection"""
        print("ğŸ” Testing OpenAI Embedding API...")
        
        try:
            start_time = time.time()
            
            # Initialize embedding service
            embedding_service = EmbeddingService()
            
            # Test embedding with a simple text
            test_text = "Bu bir API baÄŸlantÄ± testidir."
            
            embedding = await embedding_service.generate_embedding(test_text)
            
            end_time = time.time()
            
            result = {
                "status": "SUCCESS",
                "response_time": round((end_time - start_time) * 1000, 2),  # ms
                "embedding_dimension": len(embedding) if embedding else 0,
                "api_key_valid": True,
                "model_used": self.settings.OPENAI_EMBEDDING_MODEL,
                "error": None
            }
            
            print(f"âœ… OpenAI Embedding: SUCCESS ({result['response_time']}ms)")
            print(f"   Model: {result['model_used']}")
            print(f"   Dimension: {result['embedding_dimension']}")
            
            return result
            
        except Exception as e:
            result = {
                "status": "FAILED",
                "response_time": None,
                "embedding_dimension": 0,
                "api_key_valid": False,
                "model_used": self.settings.OPENAI_EMBEDDING_MODEL,
                "error": str(e)
            }
            
            print(f"âŒ OpenAI Embedding: FAILED")
            print(f"   Error: {str(e)}")
            
            return result
    
    async def test_groq_inference(self) -> Dict[str, Any]:
        """Test Groq inference API connection"""
        print("ğŸ§  Testing Groq AI Inference API...")
        
        try:
            start_time = time.time()
            
            # Initialize Groq service
            groq_service = GroqService()
            
            # Test AI inference with a simple prompt
            test_prompt = "Merhaba, bu bir API test mesajÄ±dÄ±r."
            test_context = "Bu bir test baÄŸlamÄ±dÄ±r."
            
            response = await groq_service.generate_response(
                prompt=test_prompt,
                context=test_context,
                max_tokens=100,
                temperature=0.1
            )
            
            end_time = time.time()
            
            result = {
                "status": "SUCCESS",
                "response_time": round((end_time - start_time) * 1000, 2),  # ms
                "response_length": len(response.get("response", "")),
                "api_key_valid": True,
                "model_used": response.get("model_used", "unknown"),
                "token_usage": response.get("token_usage", {}),
                "confidence_score": response.get("confidence_score", 0.0),
                "error": None
            }
            
            print(f"âœ… Groq Inference: SUCCESS ({result['response_time']}ms)")
            print(f"   Model: {result['model_used']}")
            print(f"   Response Length: {result['response_length']} chars")
            print(f"   Confidence: {result['confidence_score']:.2f}")
            
            return result
            
        except Exception as e:
            result = {
                "status": "FAILED",
                "response_time": None,
                "response_length": 0,
                "api_key_valid": False,
                "model_used": "llama3-8b-8192",
                "token_usage": {},
                "confidence_score": 0.0,
                "error": str(e)
            }
            
            print(f"âŒ Groq Inference: FAILED")
            print(f"   Error: {str(e)}")
            
            return result
    
    async def test_combined_pipeline(self) -> Dict[str, Any]:
        """Test combined OpenAI + Groq pipeline"""
        print("ğŸ”„ Testing Combined AI Pipeline...")
        
        try:
            start_time = time.time()
            
            # Test full pipeline: embedding + inference
            test_query = "TÃ¼rkiye'de ÅŸirket kurmak iÃ§in gerekli belgeler nelerdir?"
            
            # Step 1: Generate embedding
            embedding_service = EmbeddingService()
            embedding = await embedding_service.generate_embedding(test_query)
            
            # Step 2: Simulate context from search results
            mock_context = """
            [KAYNAK 1]
            Belge: Åirket KuruluÅŸ Rehberi
            Kurum: Ticaret BakanlÄ±ÄŸÄ±
            Ä°Ã§erik: Åirket kurmak iÃ§in nÃ¼fus cÃ¼zdanÄ±, adres belgesi ve vergi numarasÄ± gereklidir.
            """
            
            # Step 3: Generate AI response
            groq_service = GroqService()
            ai_response = await groq_service.generate_response(
                prompt=test_query,
                context=mock_context,
                max_tokens=200,
                temperature=0.1
            )
            
            end_time = time.time()
            
            result = {
                "status": "SUCCESS",
                "total_time": round((end_time - start_time) * 1000, 2),  # ms
                "embedding_success": len(embedding) > 0 if embedding else False,
                "ai_response_success": bool(ai_response.get("response")),
                "pipeline_functional": True,
                "error": None
            }
            
            print(f"âœ… Combined Pipeline: SUCCESS ({result['total_time']}ms)")
            print(f"   Embedding: {'âœ…' if result['embedding_success'] else 'âŒ'}")
            print(f"   AI Response: {'âœ…' if result['ai_response_success'] else 'âŒ'}")
            
            return result
            
        except Exception as e:
            result = {
                "status": "FAILED",
                "total_time": None,
                "embedding_success": False,
                "ai_response_success": False,
                "pipeline_functional": False,
                "error": str(e)
            }
            
            print(f"âŒ Combined Pipeline: FAILED")
            print(f"   Error: {str(e)}")
            
            return result
    
    async def run_all_tests(self):
        """Run all API connection tests"""
        print("ğŸš€ MevzuatGPT API Connection Tests")
        print("=" * 50)
        
        # Test OpenAI
        openai_result = await self.test_openai_embedding()
        self.results["openai"] = openai_result
        
        print()
        
        # Test Groq
        groq_result = await self.test_groq_inference()
        self.results["groq"] = groq_result
        
        print()
        
        # Test Combined Pipeline
        pipeline_result = await self.test_combined_pipeline()
        self.results["pipeline"] = pipeline_result
        
        print()
        
        # Summary
        self.print_summary()
    
    def print_summary(self):
        """Print test results summary"""
        print("ğŸ“Š TEST SUMMARY")
        print("=" * 30)
        
        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results.values() if r["status"] == "SUCCESS")
        
        print(f"Total Tests: {total_tests}")
        print(f"Passed: {passed_tests}")
        print(f"Failed: {total_tests - passed_tests}")
        print(f"Success Rate: {(passed_tests / total_tests * 100):.1f}%")
        
        print("\nDETAILS:")
        
        if self.results.get("openai", {}).get("status") == "SUCCESS":
            openai = self.results["openai"]
            print(f"âœ… OpenAI: {openai['response_time']}ms, {openai['embedding_dimension']}D vectors")
        else:
            print("âŒ OpenAI: Connection failed")
        
        if self.results.get("groq", {}).get("status") == "SUCCESS":
            groq = self.results["groq"]
            print(f"âœ… Groq: {groq['response_time']}ms, {groq['model_used']}")
        else:
            print("âŒ Groq: Connection failed")
        
        if self.results.get("pipeline", {}).get("status") == "SUCCESS":
            pipeline = self.results["pipeline"]
            print(f"âœ… Pipeline: {pipeline['total_time']}ms end-to-end")
        else:
            print("âŒ Pipeline: Integration failed")
        
        print("\nğŸ¯ READY FOR PRODUCTION!" if passed_tests == total_tests else "\nâš ï¸  Fix failed connections before deployment")

async def main():
    """Main test runner"""
    tester = APIConnectionTester()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())